{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosting Machine (XGBoost) - With Tuned Hyperparameters\n",
    "### *Exploring the association between neoantigen-related variables and immune scores*\n",
    "This notebook is the continuation of the `xgboost.ipynb` notebook, which details hyperparameter tuning grid search with cross-validation to model interactions of select X features on a subset of Y labels (based on the PCA work done by Caitlin from GB team). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Package and Raw Data Loading**\n",
    "First, import necessary packages and load in the raw data table into `pandas` dataFrame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter, filterwarnings\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the cleaned-up dataset wrangled from MH's latest work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in latest data\n",
    "# use the 202409_new_excludedIHC_batch-duplicate-removed.tsv\n",
    "df = pd.read_csv(\"../input-data/SA/202409_new_excludedIHC_batch-duplicate-removed.tsv\",sep=\"\\t\")\n",
    "print(df.shape)\n",
    "\n",
    "#print row 107 and 226\n",
    "df.iloc[[107,226,555,872], :25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the 29 Cibersort scores, leaving only 3\n",
    "df = df.drop(columns=['Bindea_full', 'Expanded_IFNg', \n",
    "        'C_Bcellsmemory','C_Plasmacells','C_TcellsCD8','C_TcellsCD4naive',\n",
    "         'C_TcellsCD4memoryactivated','C_Tcellsfollicularhelper',\n",
    "         'C_Tcellsregulatory(Tregs)','C_Tcellsgammadelta','C_NKcellsresting',\n",
    "         'C_NKcellsactivated', 'C_Monocytes', 'C_MacrophagesM0',\n",
    "         'C_MacrophagesM1','C_Dendriticcellsresting',\n",
    "         'C_Dendriticcellsactivated', 'C_Mastcellsresting',\n",
    "         'C_Mastcellsactivated','C_Eosinophils', 'C_Neutrophils', 'S_PAM100HRD'])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Preprocessing**\n",
    "\n",
    "Decide all the clinical variables and neoantigen-related variables to keep in the X matrix (features).\n",
    "\n",
    "1. `Subtype` column has already been encoded categorically by `HR_status` and `HER_status` columns so these two columns can be dropped. ***UPDATE: due to their lesser importance during the default XGBoost modeling, `PAM50` column was dropped as well.***\n",
    "\n",
    "2.  `AgeGroup` is just a binned information of `Age` column so it is dropped as it is redundant.\n",
    "\n",
    "3. Drop `FusionNeo_bestScore`, `FusionTransscript_Count`, `Fusion_T2NeoRate` columns as well as the `SNVindelNeo_IC50` and `SNVindelNeo_IC50Percentile` columns for now to reduce complexity. \n",
    "\n",
    "> **UPDATE 1: Exclude `TotalNeo_Count`, and include `Fusion_T2NeoRate` and `SNVindelNeo_IC50` columns. Also, rename `Fusion_T2NeoRate` to `FN/FT_Ratio`.**\n",
    "\n",
    "> **UPDATE: put back `FusionNeo_bestScore` into the X variable set and rename it into `FusionNeo_bestIC50`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# subset df into just features and the immune scores as Y variables\n",
    "## DEPRECATED ## \n",
    "dfd = df.drop(columns = ['HR_status', 'HER_status', 'AgeGroup', 'FusionNeo_bestScore','FusionTransscript_Count', 'Fusion_T2NeoRate', 'SNVindelNeo_IC50', 'SNVindelNeo_IC50Percentile'])\n",
    "print(dfd.shape)\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# let's drop all NaN for now and set col 'ID' as index\n",
    "## DEPRECATED ##\n",
    "dfx = dfd.dropna().set_index('ID')\n",
    "\n",
    "print(dfx.shape)\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** Check to make sure there is no duplicated index rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "## DEPRECATED ##\n",
    "print(dfx.index[dfx.index.duplicated()].unique())\n",
    "rows_dupe = list(dfx.index[dfx.index.duplicated()].unique())\n",
    "rows_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd2 = df.drop(columns = ['PAM50', 'HR_status', 'HER_status', 'AgeGroup', 'TotalNeo_Count', 'SNVindelNeo_IC50Percentile'])\n",
    "print(dfd2.shape)\n",
    "dfd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop all NaN for now and set col 'ID' as index\n",
    "dfx2 = dfd2.dropna().set_index('ID')\n",
    "print(dfx2.shape)\n",
    "dfx2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column `Fusion_T2NeoRate` to `FN/FT_Ratio` and `FusionNeo_bestScore` to `FusionNeo_bestIC50`\n",
    "dfx2.rename(columns={'Fusion_T2NeoRate': 'FN/FT_Ratio'}, inplace=True)\n",
    "dfx2.rename(columns={'FusionNeo_bestScore': 'FusionNeo_bestIC50'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfx2.index[dfx2.index.duplicated()].unique())\n",
    "rows_dupe = list(dfx2.index[dfx2.index.duplicated()].unique())\n",
    "rows_dupe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: ~~Initially we put `IMPRES` score as part of the target variable set, but it might be more informative to put this column as part of the X variable set, as they describe predictions on ICI response of patients (responders or not). In other words we are not exactly asking the question, \"does neoantigen count correlate with patient response to ICI?\" (though this is a valid question), so including IMPRES as Y variable might muddle our modeling. Similarly, `ESTIMATE` score is a hybrid tumor purity score that serves as a function of two components derived from ssGSEA: the immune score and the stromal score associated with a tumor sample. So, in this manner, this attribute is closer to being a relevant, potentially informative clinical variable to be used as a feature than a response/target variable.~~\n",
    "\n",
    "> **UPDATE**: I have decided to keep these two columns as part of the Y variable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# dfw = dfdix.copy()\n",
    "\n",
    "# # first pop these columns\n",
    "# impres_col = dfw.pop('IMPRES')\n",
    "# estimate_col = dfw.pop('ESTIMATE')\n",
    "\n",
    "# # then insert it at the second position\n",
    "# dfw.insert(7, 'IMPRES', impres_col)\n",
    "# dfw.insert(8, 'ESTIMATE', estimate_col)\n",
    "\n",
    "# dfw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can encode categorical variables and integer variables accordingly so they are more amenable to machine learning algorithms. \n",
    "\n",
    "Modify the values in the Batch column and then check data types of the resulting cleaned up dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# re-encode the Batch column into 1 or 2\n",
    "## DEPRECATED ##\n",
    "dfx['Batch'] = dfx['Batch'].apply(lambda x: 1 if x == 'Batch_1' else 2)\n",
    "dfx.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "We need to encode the two `object` columns into categorical numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "## DEPRECATED ##\n",
    "dfx['Subtype'].astype('category')\n",
    "dfx['PAM50'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx2['Subtype'].astype('category')\n",
    "dfx2['Batch'] = dfx2['Batch'].apply(lambda x: 1 if x == 'Batch_1' else 2)\n",
    "dfx2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(dfx2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode the `object` columns into appropriate types. Change `Stage`, `Age`, `TumorGrade`, and `IMPRES` into `int64` as well as all `*_Count` columns because they are discrete variables. Change the `FN/FT_Ratio` into `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# change Stage and Age column into int64\n",
    "## DEPRECATED ##\n",
    "dfx['Stage'] = dfx['Stage'].astype('int64')\n",
    "dfx['Age'] = dfx['Age'].astype('int64')\n",
    "dfx['IMPRES'] = dfx['IMPRES'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change Stage and Age column into int64\n",
    "dfx2['Stage'] = dfx2['Stage'].astype('int64')\n",
    "dfx2['Age'] = dfx2['Age'].astype('int64')\n",
    "dfx2['TumorGrade'] = dfx2['TumorGrade'].astype('int64')\n",
    "dfx2['IMPRES'] = dfx2['IMPRES'].astype('int64')\n",
    "dfx2['FusionNeo_Count'] = dfx2['FusionNeo_Count'].astype('int64')\n",
    "dfx2['FusionTransscript_Count'] = dfx2['FusionTransscript_Count'].astype('int64')\n",
    "dfx2['SNVindelNeo_Count'] = dfx2['SNVindelNeo_Count'].astype('int64')\n",
    "dfx2['FN/FT_Ratio'] = dfx2['FN/FT_Ratio'].astype('float64')\n",
    "\n",
    "print(dfx2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use Feature_Engine's `OneHotEncoder()` to create a `k` dummy variable set for `PAM50` and `Subtype`.\n",
    "\n",
    "**NOTE**: The encoded columns will be appended at the end of the dataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    variables=['Subtype'],\n",
    "    drop_last=False,\n",
    "    )\n",
    "\n",
    "encoder.fit(dfx2)\n",
    "df_tmp = encoder.transform(dfx2)\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the encoded columns to shift\n",
    "enc_cols = ['Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+']\n",
    "\n",
    "# Drop the specified columns and store them\n",
    "encoded_col_df = df_tmp[enc_cols]\n",
    "dfx2_ = dfx2.drop(columns=['Subtype'])\n",
    "\n",
    "# Specify the index where you want to reinsert the columns\n",
    "insert_index = 1  # This will insert after the first column\n",
    "\n",
    "# Reinsert the columns\n",
    "for i, col in enumerate(encoded_col_df.columns):\n",
    "    dfx2_.insert(insert_index + i, col, encoded_col_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the categorically-encoded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfx2_.shape)\n",
    "dfx2_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below is the original, unencoded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfx2.shape)\n",
    "dfx2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spearman Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on with XGBoost, we can plot a Spearman correlation matrix between the clinical variables (X features) and the immune score variables (Y labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropcat = dfx2.drop(columns=['Batch', 'Subtype'])\n",
    "print(df_dropcat.shape)\n",
    "df_dropcat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replot heatmap on transformed data\n",
    "corr_df = df_dropcat.corr(method='spearman')\n",
    "corr_df = corr_df.round(2)\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_df, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(46, 36))\n",
    "\n",
    "# Create the correlation matrix and represent it as a heatmap.\n",
    "hm = sns.heatmap(corr_df, annot = False, cmap = 'RdBu_r', square = True, linewidths=0.5, center=0, mask=mask, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Get current labels\n",
    "ylabels = hm.get_yticklabels()\n",
    "xlabels = hm.get_xticklabels()\n",
    "\n",
    "# Hide the first y-axis label and the last x-axis label\n",
    "ylabels[0].set_visible(False)\n",
    "xlabels[-1].set_visible(False)\n",
    "\n",
    "# Rotate and align the tick labels\n",
    "plt.setp(xlabels, rotation=45, ha='right')\n",
    "\n",
    "# Define columns to highlight and their colors\n",
    "highlight_cols = {\n",
    "    \"TotalNeo_Count\": \"crimson\",\n",
    "    \"FusionNeo_Count\": \"olive\",\n",
    "    \"SNVindelNeo_Count\": \"darkviolet\"\n",
    "}\n",
    "\n",
    "# Change color of specific x-axis and y-axis labels\n",
    "for label in xlabels:\n",
    "    if label.get_text() in highlight_cols:\n",
    "        label.set_color(highlight_cols[label.get_text()])\n",
    "        label.set_fontweight('bold')\n",
    "\n",
    "for label in ylabels:\n",
    "    if label.get_text() in highlight_cols:\n",
    "        label.set_color(highlight_cols[label.get_text()])\n",
    "        label.set_fontweight('bold')\n",
    "\n",
    "# Removes all ticks\n",
    "hm.tick_params(left=False, bottom=False)\n",
    "\n",
    "hm.set_title('Dataframe Correlation Heatmap', fontsize=30, x=0.45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "\n",
    "#### **Distributions of Neoantigen Counts by Subtype and PAM50 Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Then, plot the distributions of `FusionNeo_Count`, `SNVindelNeo_Count`, `TotalNeo_Count` hued by `Subtype` as boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a 3x2 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 24))\n",
    "\n",
    "# Flatten the 2D array of axes for easier indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "# List of y-variables and their corresponding titles\n",
    "y_vars = ['FusionNeo_Count', 'SNVindelNeo_Count', 'TotalNeo_Count']\n",
    "titles = [\n",
    "    'Distribution of log(Fusion Neoantigen Count)',\n",
    "    'Distribution of log(SNV & Indel Neoantigen Count)',\n",
    "    'Distribution of log(Total Neoantigen Count)'\n",
    "]\n",
    "\n",
    "# Plot Subtype boxplots on the left side\n",
    "for i, (y_var, title) in enumerate(zip(y_vars, titles)):\n",
    "    sns.boxplot(x=\"Subtype\", y=y_var, data=dfx, hue=\"Subtype\", ax=axs[i*2], palette=\"Set3\")\n",
    "    axs[i*2].set_title(f\"{title} by Subtype\")\n",
    "\n",
    "# Plot PAM50 boxplots on the right side\n",
    "for i, (y_var, title) in enumerate(zip(y_vars, titles)):\n",
    "    sns.boxplot(x=\"PAM50\", y=y_var, data=dfx, hue=\"PAM50\", ax=axs[i*2+1], palette=\"colorblind\")\n",
    "    axs[i*2+1].set_title(f\"{title} by PAM50\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis objects\n",
    "fig, axs = plt.subplots(nrows=3, figsize=(8, 12))\n",
    "\n",
    "# Plot the first subplot\n",
    "sns.kdeplot(data=dfx, x=\"FusionNeo_Count\", hue=\"PAM50\", ax=axs[0], common_norm=False)\n",
    "axs[0].set_title(\"Distribution of FusionNeo_Count by PAM50\")\n",
    "\n",
    "# Plot the second subplot\n",
    "sns.kdeplot(data=dfx, x=\"SNVindelNeo_Count\", hue=\"PAM50\", ax=axs[1], common_norm=False)\n",
    "axs[1].set_title(\"Distribution of SNVindelNeo_Count by PAM50\")\n",
    "\n",
    "# Plot the third subplot\n",
    "sns.kdeplot(data=dfx, x=\"TotalNeo_Count\", hue=\"PAM50\", ax=axs[2], common_norm=False)\n",
    "axs[2].set_title(\"Distribution of TotalNeo_Count by PAM50\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing strikes as interesting here. In a way this might be good, because this shows that there probably isn't any multicollinearity between the neoantigen count X variables and the subtype X variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Yeo-Johnson Transformation and Z-Score Standardization**\n",
    "Yeo-Johnson transformation is an extension of the Box-Cox transformation, which falls under the power transformation family. YJ algorithm is designed to handle both positive and negative values in the dataset. Similar to Box-Cox, the Yeo-Johnson transformation aims to stabilize variance, make the data more symmetric, and bring it closer to a normal distribution.\n",
    "\n",
    "Instead of doing a simple log transformation we will use YJ transformation.\n",
    "\n",
    "**NOTE**: ~~MH also performed z-score standardization following YJ transformation but that might be unnecessary.~~ **UPDATE:** ~~I changed my mind. Z-score helped center the data which would be useful for some machine learning algorithms. Let's do that.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df_dropcat.copy()\n",
    "print(dfc.shape)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise distributions\n",
    "# Determine the number of rows and columns for the subplot grid\n",
    "nrows = 10\n",
    "ncols = 13\n",
    "\n",
    "#define the plotting function\n",
    "def visualize_distribution(df, naming_class, colr):\n",
    "    # Create a figure and a grid of subplots\n",
    "    # Flatten the axes array for easy iteration\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 22))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot histograms for each column\n",
    "    for i, column in enumerate(df.columns):\n",
    "        sns.histplot(df[column], kde=False, ax=axes[i], color=colr)\n",
    "        axes[i].set_title(column)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel('')\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92) \n",
    "    plt.suptitle(f'{naming_class} Distributions of the Dataset', fontsize=20, fontweight='bold')\n",
    "    # plt.savefig(f'Distribution_before.png',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Unscaled Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute the function\n",
    "visualize_distribution(dfc, 'Original', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "# Apply Yeo-Johnson transformation to each numeric column\n",
    "yjt = YeoJohnsonTransformer()\n",
    "yjt.fit(dfc)\n",
    "df_transformed = yjt.transform(dfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power-Transformed Distribution (YJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute the function\n",
    "visualize_distribution(df_transformed, 'YJ-Transformed', 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Apply Z-score normalization to the transformed data\n",
    "# using lambda function to apply z-score to each column and then join the resulting dataframes\n",
    "zscore = lambda x : stats.zscore(x)\n",
    "df_tfz = df_transformed.apply(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power-Transformed, Z-Scaled Distribution (YJ-Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute the function\n",
    "visualize_distribution(df_tfz, 'YJZ-Transformed', 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit StandardScaler and transform the data\n",
    "scaled_array = scaler.fit_transform(df_transformed)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "# This preserves the original column names and index\n",
    "df_scaled = pd.DataFrame(scaled_array, columns=df_transformed.columns, index=df_transformed.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power-Transformed, Standard-Scaled Distribution (YJ-SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution(df_scaled, 'YJ-transformed-standardized', 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: The distributions after the power transformation and standardization looks variance-stabilized now with a centered data around 0. Let us proceed with the dataset splitting and then data scaling using YJ and Z-score.\n",
    "\n",
    "**UPDATE:** Instead of using scipy's `zscore` we use Scikit-Learn's `StandardScaler` which is more amenable to Pipelining off Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Split Dataset with `train_test_split`**\n",
    "\n",
    "Going back to the original dataframe, we need to split the dataset before modeling to avoid information leakage, then transform the data accordingly as above. First, load the cleaned up dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 8)\n",
    "dfx2_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now list all the clinical features that would be the X variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_features = ['Age', 'TumorGrade', 'TumourSize', 'Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+', 'FusionNeo_Count', 'FusionNeo_bestIC50', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the X features that we will use for the modeling from the cleaned up dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X features; use the clin_features list generated before\n",
    "X = dfx2_[clin_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now grab the Y targets (do this as a whole, but we will train on each column individually later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the Y variable set\n",
    "cols_y = [col for col in dfx2_.drop(columns=['Batch', 'Stage', 'FusionTransscript_Count']).columns if col not in X.columns]\n",
    "Y = dfx2_[list(cols_y)]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform train test split on the X and Y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, Y_train, Y_test = skl.model_selection.train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't want to transform all the X columns (because some of them are discrete numerical data and some of them are one-hot encoded categorical variables), we need to specify the columns to transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_to_transform = ['TumourSize', 'FusionNeo_Count', 'FusionNeo_bestIC50', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, apply the Yeo-Johnson transformation on the split datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "\n",
    "# Initialize Yeo-Johnson transformer for features to transform\n",
    "yj_transformer_X = YeoJohnsonTransformer(variables=X_vars_to_transform)\n",
    "\n",
    "# Initialize Yeo-Johnson transformer for target\n",
    "yj_transformer_Y = YeoJohnsonTransformer()\n",
    "\n",
    "# Fit and transform the training data (features)\n",
    "X_train_yj = yj_transformer_X.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted transformer (features)\n",
    "X_test_yj = yj_transformer_X.transform(X_test)\n",
    "\n",
    "# Fit and transform the training data (targets)\n",
    "Y_train_yj = yj_transformer_Y.fit_transform(Y_train)\n",
    "\n",
    "# Transform the test data using the fitted transformer (targets)\n",
    "Y_test_yj = yj_transformer_Y.transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_inversed = yj_transformer_Y.inverse_transform(Y_test_yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_inversed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPRECATED** ~~Then, apply z-score standardization.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# from scipy.stats import zscore\n",
    "# # Apply Z-score normalization to Yeo-Johnson transformed columns\n",
    "# for col in X_vars_to_transform:\n",
    "#     X_train_tf[col] = zscore(X_train_tf[col])\n",
    "#     X_test_tf[col] = zscore(X_test_tf[col])\n",
    "\n",
    "# X_train_tfz = X_train_tf.copy()\n",
    "# X_test_tfz = X_test_tf.copy()\n",
    "\n",
    "# # using lambda function to apply z-score to each column\n",
    "# zs = lambda x : zscore(x)\n",
    "# Y_train_tfz = Y_train_tf.apply(zs)\n",
    "# Y_test_tfz = Y_test_tf.apply(zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Standard Scaler instead (but wrap with with `feature_engine`'s wrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "# select variables to transform\n",
    "cols_X = X_train_yj.columns.tolist()\n",
    "cols_X = [col for col in cols_X if col not in ['Age', 'TumorGrade', 'Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+']]\n",
    "\n",
    "# set up the wrapper with the StandardScaler\n",
    "scaler_X = SklearnTransformerWrapper(transformer = StandardScaler(),\n",
    "                                    variables = cols_X)\n",
    "\n",
    "# fit the wrapper + StandardScaler\n",
    "scaler_X.fit(X_train_yj)\n",
    "\n",
    "# transform the data\n",
    "X_train_yjz = scaler_X.transform(X_train_yj)\n",
    "X_test_yjz = scaler_X.transform(X_test_yj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yjz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test if we can inverse-transform the Scaler step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yj_inversed = scaler_X.inverse_transform(X_train_yjz)\n",
    "X_train_yj_inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_yj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables to transform for Y\n",
    "cols_Y = Y_train_yj.columns.tolist()\n",
    "\n",
    "# set up the wrapper with the StandardScaler\n",
    "scaler_Y = SklearnTransformerWrapper(transformer = StandardScaler(),\n",
    "                                    variables = cols_Y)\n",
    "\n",
    "# fit the wrapper + StandardScaler\n",
    "scaler_Y.fit(Y_train_yj)\n",
    "\n",
    "# transform the data\n",
    "Y_train_yjz = scaler_Y.transform(Y_train_yj)\n",
    "Y_test_yjz = scaler_Y.transform(Y_test_yj)\n",
    "Y_train_yjz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create a Pipeline from `feature_engine` Package**\n",
    "This would enable easy inverse transform steps for both X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.pipeline import Pipeline\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_vars_to_transform = ['TumourSize', 'FusionNeo_Count', 'FusionNeo_bestIC50', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']\n",
    "\n",
    "# select variables to scale\n",
    "scale_cols_X = X_train.columns.tolist()\n",
    "scale_cols_X = [col for col in scale_cols_X if col not in ['Age', 'TumorGrade', 'Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+']]\n",
    "\n",
    "# Create the pipeline\n",
    "preprocess_pipeline_X = Pipeline([\n",
    "    ('yeo_johnson', YeoJohnsonTransformer(variables=X_vars_to_transform)),\n",
    "    ('scaler', SklearnTransformerWrapper(transformer = StandardScaler(), variables = scale_cols_X))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "preprocess_pipeline_X.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_yjsc = preprocess_pipeline_X.transform(X_train)\n",
    "# Transform the test data\n",
    "X_test_yjsc = preprocess_pipeline_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yjz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yjsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try inverse transform on the pipeline\n",
    "X_train_inv = preprocess_pipeline_X.inverse_transform(X_train_yjsc)\n",
    "X_train_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pipeline worked! Now we can do the same with Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.pipeline import Pipeline\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# select variables to scale\n",
    "scale_cols_Y = Y_train.columns.tolist()\n",
    "\n",
    "# Create the pipeline\n",
    "preprocess_pipeline_Y = Pipeline([\n",
    "    ('yeo_johnson', YeoJohnsonTransformer()),\n",
    "    ('scaler', SklearnTransformerWrapper(transformer = StandardScaler(), variables = scale_cols_Y))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "preprocess_pipeline_Y.fit(Y_train)\n",
    "\n",
    "# Transform the training data\n",
    "Y_train_yjsc = preprocess_pipeline_Y.transform(Y_train)\n",
    "# Transform the test data\n",
    "Y_test_yjsc = preprocess_pipeline_Y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_yjz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_yjsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try inverse transform\n",
    "Y_test_inv = preprocess_pipeline_Y.inverse_transform(Y_test_yjsc)\n",
    "Y_test_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **XGBoost Learning**\n",
    "\n",
    "Time to test XGBoost. Select `ESTIMATE` column as the first target/label (`y`) variable first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ESTIMATE column as y label\n",
    "y_target = 'ESTIMATE'\n",
    "Y_train_targ = Y_train_yjsc[y_target]\n",
    "Y_test_targ = Y_test_yjsc[y_target]\n",
    "\n",
    "print(Y_train_targ.shape)\n",
    "print(Y_test_targ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `y` label selected, create DMatrix objects for XGBoost corresponding to the `X_train_yjsc` and `X_test_yjsc` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for XGBoost; enable_categorical=True if there are categorical encoded columns\n",
    "dtrain = xgb.DMatrix(X_train_yjsc, label=Y_train_targ, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test_yjsc, label=Y_test_targ, enable_categorical=True)\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 150\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions\n",
    "y_transformed_preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_transformed_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Now that XGBoost training and modeling have been completed, we can reverse the Z-score scaling and YJ transformation in the order they were applied. Make sure to use the pre-scaled mean and standard deviation for the z-score reversal.~~\n",
    "\n",
    "Use the Pipeline object to inverse transform. Make sure to make a dummy dataFrame for the predicted Y array first because the Pipeline object were created based off a dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# mean_y = Y_train_tf[y_index].mean()\n",
    "# print(mean_y)\n",
    "# std_y = Y_train_tf[y_index].std()\n",
    "# print(std_y)\n",
    "# # Step 1: Reverse Z-score normalization\n",
    "# preds_rev_z = (preds_tf * std_y) + mean_y\n",
    "# preds_rev_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the same columns as the original y used in fit\n",
    "dummy_y = pd.DataFrame(0, index=X_test_yjsc.index, columns=Y_test_yjsc.columns)\n",
    "dummy_y[y_target] = y_transformed_preds\n",
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply inverse transform\n",
    "dummy_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_y)\n",
    "dummy_y_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant target column\n",
    "y_preds = dummy_y_inv[y_target].to_numpy()\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Evaluation**\n",
    "\n",
    "Import Scikit-Learn's `metrics` tools to evaluate the machine learning outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test[y_target], y_preds))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "mae = mean_absolute_error(Y_test[y_target], y_preds)\n",
    "r2 = r2_score(Y_test[y_target], y_preds)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth keeping in mind that these metrics are based on one split of the full dataset (seed of 42) during the `train_test_split`, and using default hyperparameters. \n",
    "\n",
    "Regardless, let's look at the built-in feature importance plots as well as SHAP-analyzed feature importance plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_importance(model, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train_yjsc)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_train_yjsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values on the test set\n",
    "shap_values_test = explainer.shap_values(X_test_yjsc)\n",
    "\n",
    "# Summary plot for test set\n",
    "shap.summary_plot(shap_values_test, X_test_yjsc)\n",
    "\n",
    "# Optionally, you can still calculate and compare with training set\n",
    "shap_values_train = explainer.shap_values(X_train_yjsc)\n",
    "\n",
    "# Compare summary plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(121)\n",
    "shap.summary_plot(shap_values_test, X_test_yjsc, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Test Set SHAP Values\")\n",
    "plt.subplot(122)\n",
    "shap.summary_plot(shap_values_train, X_train_yjsc, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Train Set SHAP Values\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance based on mean absolute SHAP values\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "feature_importance_df = pd.DataFrame(list(zip(X_test_yjsc.columns, feature_importance)),\n",
    "                                     columns=['feature', 'importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features by SHAP importance based on the test set:\")\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance_df.plot(x='feature', y='importance', kind='bar')\n",
    "plt.title('Feature Importance (Mean Absolute SHAP Values)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean |SHAP Value|')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# SHAP dependence plot for the most important feature\n",
    "# most_important_feature = feature_importance_df.iloc[0]['feature']\n",
    "# shap.dependence_plot(most_important_feature, shap_values, X_train_tfz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_train_yjsc)\n",
    "\n",
    "# Perform clustering\n",
    "clust = shap.utils.hclust(X_train_yjsc, Y_train_targ)\n",
    "\n",
    "# Create the bar plot with clustering\n",
    "shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_test_yjsc)\n",
    "\n",
    "# Perform clustering\n",
    "clust = shap.utils.hclust(X_test_yjsc, Y_test_targ)\n",
    "\n",
    "# Create the bar plot with clustering\n",
    "shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainers\n",
    "explainer_original = shap.TreeExplainer(model)\n",
    "explainer_transformed = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values_original = explainer_original(X_test)\n",
    "shap_values_transformed = explainer_transformed(X_test_yjsc)\n",
    "\n",
    "# Function to plot and compare SHAP summary plots\n",
    "def compare_shap_plots(shap_values_orig, shap_values_trans, X_orig, X_trans):\n",
    "    plt.figure(figsize=(60, 30))\n",
    "    plt.subplot(121)\n",
    "    shap.summary_plot(shap_values_orig, X_orig, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"SHAP Values - Original Features\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    shap.summary_plot(shap_values_trans, X_trans, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"SHAP Values - Transformed Features\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Compare SHAP plots\n",
    "compare_shap_plots(shap_values_original, shap_values_transformed, X_test, X_test_yjsc)\n",
    "\n",
    "# Function to get feature importance from SHAP values\n",
    "def get_feature_importance(shap_values, feature_names):\n",
    "    feature_importance = np.abs(shap_values.values).mean(0)\n",
    "    feature_importance_df = pd.DataFrame(list(zip(feature_names, feature_importance)),\n",
    "                                         columns=['feature', 'importance'])\n",
    "    return feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# Get and compare feature importances\n",
    "importance_original = get_feature_importance(shap_values_original, X_test.columns)\n",
    "importance_transformed = get_feature_importance(shap_values_transformed, X_test.columns)\n",
    "\n",
    "# print(\"Top 10 features (Original):\")\n",
    "# print(importance_original.head(10))\n",
    "# print(\"\\nTop 10 features (Transformed):\")\n",
    "# print(importance_transformed.head(10))\n",
    "\n",
    "# For specific feature analysis, use dependence plots\n",
    "# shap.dependence_plot(importance_original.iloc[2]['feature'], shap_values_original.values, X_train)\n",
    "# shap.dependence_plot(importance_transformed.iloc[2]['feature'], shap_values_transformed.values, X_train_tfz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Packaging the ML Workflow for Iterative Analyses**\n",
    "\n",
    "The code above is running XGBoost using its native API. Let's rerun XGBoost using `scikit-learn` API. Expect similar output because different interfaces are cosmetic and should not affect underlying computation. Many of the steps will be packaged into functions as well to allow iterative analyses on different Y target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "### DEPRECATED ###\n",
    "# dfc_updated = dfc.drop(columns=['Stage', 'FusionTransscript_Count', 'Age'])\n",
    "# clin_features = ['TumorGrade', 'TumourSize', 'FusionNeo_bestIC50', 'FusionNeo_Count', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']\n",
    "# # define X features; use the clin_features list generated before\n",
    "# X = dfc_updated[clin_features]\n",
    "\n",
    "# # Now get the Y variable set\n",
    "# cols_y = [col for col in dfc_updated.columns if col not in X.columns]\n",
    "# Y = dfc_updated[list(cols_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `Stage` and `FusionTransscript_Count` features as they are deemed less important in the SHAP analysis above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = dfx2_.drop(columns=['Batch', 'Stage', 'FusionTransscript_Count'])\n",
    "\n",
    "clin_features = ['Age', 'TumorGrade', 'TumourSize', 'Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+', 'FusionNeo_Count', 'FusionNeo_bestIC50', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']\n",
    "\n",
    "X = dfc[clin_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Y set\n",
    "cols_y = [col for col in dfc.columns if col not in X.columns]\n",
    "Y = dfc[list(cols_y)]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, Y_train, Y_test = skl.model_selection.train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules for transformation\n",
    "from feature_engine.pipeline import Pipeline\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# select X features to transform\n",
    "X_vars_to_transform = ['TumourSize', 'FusionNeo_Count', 'FusionNeo_bestIC50', 'FN/FT_Ratio', 'SNVindelNeo_Count', 'SNVindelNeo_IC50']\n",
    "\n",
    "# select variables to scale\n",
    "scale_cols_X = X_train.columns.tolist()\n",
    "scale_cols_X = [col for col in scale_cols_X if col not in ['Age', 'TumorGrade', 'Subtype_HR+/HER2-', 'Subtype_HR+/HER2+', 'Subtype_TNBC', 'Subtype_HR-/HER2+']]\n",
    "\n",
    "# Create the pipeline\n",
    "preprocess_pipeline_X = Pipeline([\n",
    "    ('yeo_johnson', YeoJohnsonTransformer(variables=X_vars_to_transform)),\n",
    "    ('scaler', SklearnTransformerWrapper(transformer = StandardScaler(), variables = scale_cols_X))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "preprocess_pipeline_X.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_yjsc = preprocess_pipeline_X.transform(X_train)\n",
    "# Transform the test data\n",
    "X_test_yjsc = preprocess_pipeline_X.transform(X_test)\n",
    "\n",
    "#### Y Labels ####\n",
    "# select variables to scale\n",
    "scale_cols_Y = Y_train.columns.tolist()\n",
    "\n",
    "# Create the pipeline\n",
    "preprocess_pipeline_Y = Pipeline([\n",
    "    ('yeo_johnson', YeoJohnsonTransformer()),\n",
    "    ('scaler', SklearnTransformerWrapper(transformer = StandardScaler(), variables = scale_cols_Y))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "preprocess_pipeline_Y.fit(Y_train)\n",
    "\n",
    "# Transform the training data\n",
    "Y_train_yjsc = preprocess_pipeline_Y.transform(Y_train)\n",
    "# Transform the test data\n",
    "Y_test_yjsc = preprocess_pipeline_Y.transform(Y_test)\n",
    "\n",
    "print(\"Shapes after transformations:\")\n",
    "print(\"Transformed X_train:\", X_train_yjsc.shape)\n",
    "print(\"Transformed X_test:\", X_test_yjsc.shape)\n",
    "print(\"Transformed Y_train:\", Y_train_yjsc.shape)\n",
    "print(\"Transformed Y_test:\", Y_test_yjsc.shape)\n",
    "\n",
    "# Extract ESTIMATE column as y label\n",
    "y_target = 'ESTIMATE'\n",
    "y_train_targ = Y_train_yjsc[y_target]\n",
    "y_test_targ = Y_test_yjsc[y_target]\n",
    "print(y_train_targ)\n",
    "print(y_test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgbreg = XGBRegressor(n_estimators=150, random_state=42)\n",
    "\n",
    "# fit\n",
    "model_xgbreg.fit(X_train_yjsc, y_train_targ)\n",
    "\n",
    "# predict\n",
    "y_transformed_train_pred = model_xgbreg.predict(X_train_yjsc)\n",
    "y_transformed_test_pred = model_xgbreg.predict(X_test_yjsc)\n",
    "\n",
    "# Create a DataFrame with the same columns as the original y used in fit\n",
    "dummy_train_y = pd.DataFrame(0, index=X_train_yjsc.index, columns=Y_train_yjsc.columns)\n",
    "dummy_train_y[y_target] = y_transformed_train_pred\n",
    "\n",
    "dummy_test_y = pd.DataFrame(0, index=X_test_yjsc.index, columns=Y_test_yjsc.columns)\n",
    "dummy_test_y[y_target] = y_transformed_test_pred\n",
    "\n",
    "# apply inverse transform\n",
    "dummy_train_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_train_y)\n",
    "dummy_test_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_test_y)\n",
    "\n",
    "# Extract the relevant target column\n",
    "y_train_pred = dummy_train_y_inv[y_target].to_numpy()\n",
    "y_test_pred = dummy_test_y_inv[y_target].to_numpy()\n",
    "\n",
    "# Evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(Y_train[y_target], y_train_pred)\n",
    "test_r2 = r2_score(Y_test[y_target], y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(Y_train[y_target], y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(Y_test[y_target], y_test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(Y_train[y_target], y_train_pred)\n",
    "test_mae = mean_absolute_error(Y_test[y_target], y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance:\")\n",
    "print(f\"{'Metric':<10} {'Train':<10} {'Test':<10}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'R2':<10} {train_r2:<10.4f} {test_r2:<10.4f}\")\n",
    "print(f\"{'RMSE':<10} {train_rmse:<10.4f} {test_rmse:<10.4f}\")\n",
    "print(f\"{'MAE':<10} {train_mae:<10.4f} {test_mae:<10.4f}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.scatter(Y_train[y_target], y_train_pred, alpha=0.5)\n",
    "ax1.plot([Y_train[y_target].min(), Y_train[y_target].max()], [Y_train[y_target].min(), Y_train[y_target].max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.set_title('Train Set')\n",
    "\n",
    "ax2.scatter(Y_test[y_target], y_test_pred, alpha=0.5)\n",
    "ax2.plot([Y_test[y_target].min(), Y_test[y_target].max()], [Y_test[y_target].min(), Y_test[y_target].max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual')\n",
    "ax2.set_ylabel('Predicted')\n",
    "ax2.set_title('Test Set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "##### OBSOLETE\n",
    "# rmse = np.sqrt(mean_squared_error(Y_test[y_target], y_test_pred))\n",
    "# print(f\"RMSE: {rmse}\")\n",
    "# mae = mean_absolute_error(Y_test[y_target], y_test_pred)\n",
    "# r2 = r2_score(Y_test[y_target], y_test_pred)\n",
    "# print(f\"Mean Absolute Error: {mae}\")\n",
    "# print(f\"R-squared Score: {r2}\")\n",
    "\n",
    "# Feature importance\n",
    "fig, ax = plt.subplots(figsize=(18, 16), dpi=300)\n",
    "plot_importance(model_xgbreg, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "import shap\n",
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model_xgbreg)\n",
    "\n",
    "# run explanation object on X_test dataset because we don't want to learn what the model learned from the X_train data, but to see features that would influence predictions on new data\n",
    "shap_values = explainer(X_test_yjsc)\n",
    "\n",
    "plt.figure(figsize=(18, 16)) \n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, show=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform clustering\n",
    "clust = shap.utils.hclust(X_test_yjsc, y_test_targ)\n",
    "# Create the bar plot with clustering\n",
    "plt.figure(figsize=(18, 16)) \n",
    "shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1, show=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Iterative Learning over all Y labels**\n",
    "\n",
    "The learning using XGBoost above was done on just one Y label, which is the `ESTIMATE` column. Let's put these into a set of functions so we can run this process iteratively on all Y columns we have set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the steps above as a function\n",
    "import os \n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "class YTargetMetrics:\n",
    "    def __init__(self, target_name, train_r2, test_r2, train_rmse, test_rmse, train_mae, test_mae):\n",
    "        self.target_name = target_name\n",
    "        self.train_r2 = train_r2\n",
    "        self.test_r2 = test_r2\n",
    "        self.train_rmse = train_rmse\n",
    "        self.test_rmse = test_rmse\n",
    "        self.train_mae = train_mae\n",
    "        self.test_mae = test_mae\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"Model Performance for {self.target_name}:\n",
    "{'Metric':<10} {'Train':<10} {'Test':<10}\n",
    "{'-' * 30}\n",
    "{'R2':<10} {self.train_r2:<10.4f} {self.test_r2:<10.4f}\n",
    "{'RMSE':<10} {self.train_rmse:<10.4f} {self.test_rmse:<10.4f}\n",
    "{'MAE':<10} {self.train_mae:<10.4f} {self.test_mae:<10.4f}\"\"\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'target_name': self.target_name,\n",
    "            'train_r2': self.train_r2,\n",
    "            'test_r2': self.test_r2,\n",
    "            'train_rmse': self.train_rmse,\n",
    "            'test_rmse': self.test_rmse,\n",
    "            'train_mae': self.train_mae,\n",
    "            'test_mae': self.test_mae\n",
    "        }\n",
    "\n",
    "def plot_learning_curves(estimator, X, y, target, cv=5, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes,\n",
    "        scoring='neg_mean_squared_error')\n",
    "    \n",
    "    train_scores_mean = -train_scores.mean(axis=1)\n",
    "    train_scores_std = train_scores.std(axis=1)\n",
    "    test_scores_mean = -test_scores.mean(axis=1)\n",
    "    test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    # Create 'plots' directory if it doesn't exist\n",
    "    os.makedirs(f'plots/{target}', exist_ok=True)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(f'plots/{target}/{target}-xgb-def-model-learning-curve.png')\n",
    "    plt.close()\n",
    "\n",
    "def run_xgboost_model(model_instance, y_target, Y_train, Y_test, X_train_transformed, X_test_transformed, Y_train_transformed, Y_test_transformed, preprocess_pipeline_Y):\n",
    "    # assign untransformed, raw target data\n",
    "    raw_y_train = Y_train[y_target]\n",
    "    raw_y_test = Y_test[y_target]\n",
    "\n",
    "    # fit\n",
    "    model_instance.fit(X_train_transformed, Y_train_transformed[y_target])\n",
    "    \n",
    "    # predict\n",
    "    y_train_pred_transformed = model_instance.predict(X_train_transformed)\n",
    "    y_test_pred_transformed = model_instance.predict(X_test_transformed)\n",
    "\n",
    "    # Create a DataFrame with the same columns as the original y used in fit\n",
    "    dummy_train_y = pd.DataFrame(0, index=X_train_transformed.index, columns=Y_train_transformed.columns)\n",
    "    dummy_train_y[y_target] = y_train_pred_transformed\n",
    "\n",
    "    dummy_test_y = pd.DataFrame(0, index=X_test_transformed.index, columns=Y_test_transformed.columns)\n",
    "    dummy_test_y[y_target] = y_test_pred_transformed\n",
    "\n",
    "    # apply inverse transform\n",
    "    dummy_train_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_train_y)\n",
    "    dummy_test_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_test_y)\n",
    "\n",
    "    # Extract the relevant target column\n",
    "    y_train_pred = dummy_train_y_inv[y_target].to_numpy()\n",
    "    y_test_pred = dummy_test_y_inv[y_target].to_numpy()\n",
    "\n",
    "    # Evaluate model\n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(raw_y_train, y_train_pred)\n",
    "    test_r2 = r2_score(raw_y_test, y_test_pred)\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(raw_y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(raw_y_test, y_test_pred))\n",
    "\n",
    "    train_mae = mean_absolute_error(raw_y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(raw_y_test, y_test_pred)\n",
    "\n",
    "    # Plot learning curves\n",
    "    plot_learning_curves(model_instance, X_train_transformed, Y_train_transformed[y_target], y_target)\n",
    "\n",
    "    # Print results\n",
    "    # print(\"Model Performance:\")\n",
    "    # print(f\"{'Metric':<10} {'Train':<10} {'Test':<10}\")\n",
    "    # print(\"-\" * 30)\n",
    "    # print(f\"{'R2':<10} {train_r2:<10.4f} {test_r2:<10.4f}\")\n",
    "    # print(f\"{'RMSE':<10} {train_rmse:<10.4f} {test_rmse:<10.4f}\")\n",
    "    # print(f\"{'MAE':<10} {train_mae:<10.4f} {test_mae:<10.4f}\")\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), dpi=300)\n",
    "\n",
    "    ax1.scatter(raw_y_train, y_train_pred, alpha=0.5)\n",
    "    ax1.plot([raw_y_train.min(), raw_y_train.max()], [raw_y_train.min(), raw_y_train.max()], 'r--', lw=2)\n",
    "    ax1.set_xlabel('Actual')\n",
    "    ax1.set_ylabel('Predicted')\n",
    "    ax1.set_title('Training Set')\n",
    "\n",
    "    ax2.scatter(raw_y_test, y_test_pred, alpha=0.5)\n",
    "    ax2.plot([raw_y_test.min(), raw_y_test.max()], [raw_y_test.min(), raw_y_test.max()], 'r--', lw=2)\n",
    "    ax2.set_xlabel('Actual')\n",
    "    ax2.set_ylabel('Predicted')\n",
    "    ax2.set_title('Testing Set')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create 'plots' directory if it doesn't exist\n",
    "    os.makedirs(f'plots/{y_target}', exist_ok=True)\n",
    "\n",
    "    plt.savefig(f'plots/{y_target}/{y_target}-xgb-def-model-performance-comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    ##### OBSOLETE\n",
    "    # rmse = np.sqrt(mean_squared_error(Y_test[y_target], y_test_pred))\n",
    "    # print(f\"RMSE: {rmse}\")\n",
    "    # mae = mean_absolute_error(Y_test[y_target], y_test_pred)\n",
    "    # r2 = r2_score(Y_test[y_target], y_test_pred)\n",
    "    # print(f\"Mean Absolute Error: {mae}\")\n",
    "    # print(f\"R-squared Score: {r2}\")\n",
    "\n",
    "    # Feature importance\n",
    "    _, ax = plt.subplots(figsize=(18, 16), dpi=300)\n",
    "    plot_importance(model_instance, ax=ax)\n",
    "\n",
    "    plt.savefig(f\"plots/{y_target}/{y_target}-xgb-def-model-test-set-feature-importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Create the SHAP explainer\n",
    "    explainer = shap.TreeExplainer(model_instance)\n",
    "\n",
    "    # run explanation object on X_test dataset because we don't want to learn what the model learned from the X_train data, but to see features that would influence predictions on new data\n",
    "    shap_values = explainer(X_test_transformed)\n",
    "\n",
    "    plt.figure(figsize=(18, 16), dpi=300) \n",
    "    # Summary plot\n",
    "    shap.summary_plot(shap_values, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{y_target}/{y_target}-xgb-def-model-test-set-SHAP-beeswarm.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Perform clustering\n",
    "    clust = shap.utils.hclust(X_test_transformed, Y_test_transformed[y_target])\n",
    "    # Create the bar plot with clustering\n",
    "    plt.figure(figsize=(18, 16)) \n",
    "    shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{y_target}/{y_target}-xgb-def-model-test-set-SHAP-summary.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Model training and evaluation for {y_target} completed.\")\n",
    "\n",
    "    # Instead of returning a tuple, return a YTargetMetrics object\n",
    "    return YTargetMetrics(y_target, train_r2, test_r2, train_rmse, test_rmse, train_mae, test_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# instantiate model\n",
    "model_xgbreg = XGBRegressor(n_estimators=150, random_state=42)\n",
    "\n",
    "for target in cols_y:\n",
    "    metrics = run_xgboost_model(model_xgbreg, target, Y_train, Y_test, X_train_yjsc, X_test_yjsc, Y_train_yjsc, Y_test_yjsc, preprocess_pipeline_Y)\n",
    "    # Store the metric result in the dictionary\n",
    "    results[target] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Now you can easily access and print metrics\n",
    "for target, metrics in results.items():\n",
    "    print(metrics)  # This will use the __str__ method of YTargetMetrics\n",
    "\n",
    "# If you need to convert back to a dictionary (e.g., for saving to JSON)\n",
    "results_dict = {target: metrics.to_dict() for target, metrics in results.items()}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open('out_files/xgboost_default_model_evaluation_metrics.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the testing R2 are poor. This means that there is an issue of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Grid Search: Using `GridSearchCV` for Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# def run_grid_search_cv(model_instance, target, param_grid, X_train_transformed, Y_train_transformed):\n",
    "#     print(target)\n",
    "\n",
    "#     # assign y target column\n",
    "#     y_train_target = Y_train_transformed[target]\n",
    "    \n",
    "#     # Set up grid search\n",
    "#     grid_search = GridSearchCV(\n",
    "#     estimator=model_instance,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     verbose=1\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Running grid search on {target} column...\")\n",
    "#     # Fit grid search\n",
    "#     grid_search.fit(X_train_transformed, y_train_target)\n",
    "\n",
    "#     # Get best parameters and model\n",
    "#     best_params = grid_search.best_params_\n",
    "#     best_model = grid_search.best_estimator_\n",
    "\n",
    "#     print(\"Best parameters:\", best_params)\n",
    "#     print(\"Best score:\", -grid_search.best_score_)\n",
    "\n",
    "#     return best_model, best_params\n",
    "\n",
    "# def predict_with_best_xgboost_model(best_model, target, X_test_transformed, Y_test_transformed, Y_test_raw, preprocess_pipeline_Y):\n",
    "#     # Make predictions on the test set using the best model\n",
    "#     y_pred_transformed = best_model.predict(X_test_transformed)\n",
    "\n",
    "#     # Create a DataFrame with the same columns as the original y used in preprocess_pipeline to reverse transformation\n",
    "#     dummy_y = pd.DataFrame(0, index=X_test_transformed.index, columns=Y_test_transformed.columns)\n",
    "#     dummy_y[target] = y_pred_transformed\n",
    "\n",
    "#     # apply inverse transform\n",
    "#     dummy_y_inv = preprocess_pipeline_Y.inverse_transform(dummy_y)\n",
    "\n",
    "#     # Extract the relevant target column\n",
    "#     y_pred = dummy_y_inv[target].to_numpy()\n",
    "\n",
    "#     # Evaluate\n",
    "#     y_test_raw = Y_test_raw[target]\n",
    "#     mae = mean_absolute_error(y_test_raw, y_pred)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test_raw, y_pred))\n",
    "#     r2 = r2_score(y_test_raw, y_pred)\n",
    "\n",
    "#     print(f\"Mean Absolute Error (MAE) [Testing]: {mae:.2f}\")\n",
    "#     print(f\"Root Mean Squared Error (RMSE) [Testing]: {rmse:.2f}\")\n",
    "#     print(f\"Coefficient of Determination (R2) [Testing]: {r2:.2f}\")\n",
    "\n",
    "#     return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate base model\n",
    "# model_xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.01, 0.1, 0.3],\n",
    "#     'subsample': [0.5, 0.8, 1.0],\n",
    "#     'gamma': [0, 0.1, 0.3, 0.8, 1]\n",
    "# }\n",
    "\n",
    "# # initialize an empty dict\n",
    "# tuned_results = {}\n",
    "\n",
    "# for target in cols_y[:2]:\n",
    "#     best_model, best_params = run_grid_search_cv(model_xgb, target, param_grid, X_train_yjsc, Y_train_yjsc)\n",
    "    \n",
    "#     tuned_metrics = predict_with_best_xgboost_model(best_model, target, X_test_yjsc, Y_test_yjsc, Y_test, preprocess_pipeline_Y)\n",
    "\n",
    "#     # Store the metric result in the dictionary\n",
    "#     tuned_results[target] = tuned_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
